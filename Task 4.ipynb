{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras import *\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    path = \"food/\"+path+\".jpg\"\n",
    "    image = tf.image.decode_jpeg(path,channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 127.5 - 1\n",
    "    image = tf.image.resize(image,(IMG_HEIGHT, IMG_WIDTH))\n",
    "    print(tf.keras.backend.shape(image))\n",
    "    return image\n",
    "\n",
    "def load_triplet(sample):\n",
    "    sample = tf.strings.split(sample)\n",
    "    baseImage = load_image(sample[0])\n",
    "    trueImage = load_image(sample[1])\n",
    "    falseImage= load_image(sample[2])\n",
    "    print(tf.keras.backend.shape(baseImage))\n",
    "    output = tf.stack([baseImage,trueImage,falseImage],axis=0)\n",
    "    print(tf.keras.backend.shape(output))\n",
    "    return output\n",
    "\n",
    "def create_dataset(filename):\n",
    "    dataset = tf.data.TextLineDataset(filename)\n",
    "    dataset.map(lambda triplet : load_triplet(triplet))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(predictions):\n",
    "    anchor, correct, wrong = predictions[...,0],predictions[...,1],predictions[...,2]\n",
    "    distance_correct = tf.reduce_sum(tf.square(anchor - correct),1)\n",
    "    distance_false = tf.reduce_sum(tf.square(anchor - wrong),1)\n",
    "    return distance_correct,distance_false\n",
    "\n",
    "def triplet_loss(_,predictions): # we use a triplet loss in this case like for facenet\n",
    "    distance_correct, distance_false = extract(predictions)\n",
    "    return tf.reduce_mean(tf.math.softplus(distance_correct - distance_false))\n",
    "   \n",
    "\n",
    "def accuracy(_,predictions):\n",
    "    distance_correct, distance_false = extract(predictions)\n",
    "    return tf.reduce_mean(tf.cast(tf.greater_equal(distance_correct,distance_false), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img, training):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img / 127.5 - 1\n",
    "    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    if training:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_triplets(triplet, training):\n",
    "    ids = tf.strings.split(triplet)\n",
    "    anchor = load_image(tf.io.read_file('food/' + ids[0] + '.jpg'), training)\n",
    "    truthy = load_image(tf.io.read_file('food/' + ids[1] + '.jpg'), training)\n",
    "    falsy = load_image(tf.io.read_file('food/' + ids[2] + '.jpg'), training)\n",
    "    if training:\n",
    "        return tf.stack([anchor, truthy, falsy], axis=0), 1\n",
    "    else:\n",
    "        return tf.stack([anchor, truthy, falsy], axis=0)\n",
    "    \n",
    "def create_dataset(dataset_filename, training=True):\n",
    "    dataset = tf.data.TextLineDataset(dataset_filename)\n",
    "    dataset = dataset.map(\n",
    "        lambda triplet: load_triplets(triplet, training),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = Input(shape=(3,IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    \n",
    "    anchor, correct,wrong = input_layer[:,0,...], input_layer[:,1,...], input_layer[:,2,...]\n",
    "    \n",
    "    encoder = MobileNetV2(include_top=False,input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    encoder.trainable = False\n",
    "    \n",
    "    decoder = Sequential([\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(256)\n",
    "    ])\n",
    "    \n",
    "    anchor_decoded = decoder(encoder(anchor))\n",
    "    correct_decoded = decoder(encoder(correct))\n",
    "    wrong_decoded = decoder(encoder(wrong))\n",
    "    \n",
    "    output_layer = tf.stack([anchor_decoded,correct_decoded,wrong_decoded],axis=-1)\n",
    "    \n",
    "    model = Model(inputs=input_layer,outputs=output_layer)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss = triplet_loss,\n",
    "                   metrics=[accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 3, 96, 96, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_36 (Sl (None, 96, 96, 3)    0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_37 (Sl (None, 96, 96, 3)    0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_38 (Sl (None, 96, 96, 3)    0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_96 (Functional (None, 3, 3, 1280)   2257984     tf.__operators__.getitem_36[0][0]\n",
      "                                                                 tf.__operators__.getitem_37[0][0]\n",
      "                                                                 tf.__operators__.getitem_38[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 256)          856064      mobilenetv2_1.00_96[0][0]        \n",
      "                                                                 mobilenetv2_1.00_96[1][0]        \n",
      "                                                                 mobilenetv2_1.00_96[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_12 (TFOpLambda)        (None, 256, 3)       0           sequential_12[0][0]              \n",
      "                                                                 sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,114,048\n",
      "Trainable params: 854,528\n",
      "Non-trainable params: 2,259,520\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "  364/10000 [>.............................] - ETA: 30:48 - loss: 30.7589 - accuracy: 0.3998"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_dataset = create_dataset('train_triplets.txt')\n",
    "    model = create_model()\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1024, reshuffle_each_iteration=True) \\\n",
    "        .repeat().batch(32)\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=int(np.ceil(10000)),\n",
    "        epochs=10,\n",
    "    )\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
