{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ATxbZ63wEMZ"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAro6yjSwEMa"
      },
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaJA-C870CHG"
      },
      "source": [
        "#introduction to machine learning would not be fun without deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvLwMJM8wEMb"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_GT-NT2wEMc"
      },
      "source": [
        "train_data = np.array(pd.read_csv('train.csv'))[:,0]\n",
        "train_solution = np.array(pd.read_csv('train.csv'))[:,1]\n",
        "test_data = np.array(pd.read_csv('test.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlLL8TpnwEMc"
      },
      "source": [
        "# Analyse dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFtN9EI1wEMc",
        "scrolled": false,
        "outputId": "80da86e1-d904-4079-99fc-b5af3040ab32"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(train_data)\n",
        "pd.read_csv('train.csv').head(8)\n",
        "full_data = np.array(pd.read_csv('train.csv'))\n",
        "unique, count = np.unique(full_data[:,1], return_counts=True)\n",
        "print(count)\n",
        "print(107787/count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112000,)\n",
            "['DKWL' 'FCHN' 'KDQP' ... 'SGHC' 'KIGT' 'PGPT']\n",
            "[107787   4213]\n",
            "[ 1.         25.58438168]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDCt_l7KwEMd"
      },
      "source": [
        "# Preprocess dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1aorGhywEMd"
      },
      "source": [
        "### Split & One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNhcw34FwEMd"
      },
      "source": [
        "def split(listwords):\n",
        "    length = listwords.shape[0]\n",
        "    output = []\n",
        "    for i in range(0,length):\n",
        "        output.append(np.array([char for char in listwords[i]]))\n",
        "    \n",
        "    return np.array(output)\n",
        "\n",
        "def onehotencode(data):\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    return encoder.fit_transform(data)\n",
        "\n",
        "encoded_train_X = onehotencode(split(train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKUemP-XwEMf"
      },
      "source": [
        "### Split for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akzZh39VwEMf",
        "scrolled": true,
        "outputId": "2fe795e4-f40a-422b-e699-efb0c8f72a16"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(encoded_train_X,train_solution,test_size = 0.0001, random_state = 42)\n",
        "X_train = encoded_train_X\n",
        "y_train = train_solution\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112000, 80)\n",
            "(112000,)\n",
            "(12, 80)\n",
            "(12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6rRh58rwEMf"
      },
      "source": [
        "# Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piAAChyJ0CHY"
      },
      "source": [
        "## source code\n",
        "#https://stackoverflow.com/questions/59963911/how-to-write-a-custom-f1-loss-function-with-weighted-average-for-keras\n",
        "## This code is just a copy paste but we are allowed to use publicy available code so it's fine\n",
        "\n",
        "def f1_weighted(true, pred):\n",
        "    ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN\n",
        "    pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP\n",
        "    true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
        "    \n",
        "    precision = true_positives / pred_positives \n",
        "    recall = true_positives / ground_positives\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "\n",
        "    weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
        "    weighted_f1 = K.sum(weighted_f1)\n",
        "\n",
        "    return weighted_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5K9iRDN00CHa"
      },
      "source": [
        "# Model declaration\n",
        "model = Sequential()\n",
        "model.add(Dense(150,input_shape=X_train[0].shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.10))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.109))\n",
        "model.add(Dense(50))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=[f1_weighted])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "565E4l8H0CHc",
        "outputId": "0e8a7a09-afe9-4a14-f399-439094caf47a"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 300\n",
        "\n",
        "weights = {0: 1, 1: 5}\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train.astype('int32'), y_train.astype('int32'),\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  verbose=True,\n",
        "                  class_weight=weights)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict_classes(X_test.astype('int32'))\n",
        "print(f1_score(y_pred,y_test.astype('int')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1750/1750 [==============================] - 1s 696us/step - loss: 0.1440 - f1_weighted: 0.4923\n",
            "Epoch 2/300\n",
            "1750/1750 [==============================] - 1s 695us/step - loss: 0.0749 - f1_weighted: 0.6594\n",
            "Epoch 3/300\n",
            "1750/1750 [==============================] - 1s 713us/step - loss: 0.0583 - f1_weighted: 0.6913\n",
            "Epoch 4/300\n",
            "1750/1750 [==============================] - 1s 716us/step - loss: 0.0496 - f1_weighted: 0.7332\n",
            "Epoch 5/300\n",
            "1750/1750 [==============================] - 1s 721us/step - loss: 0.0441 - f1_weighted: 0.7376\n",
            "Epoch 6/300\n",
            "1750/1750 [==============================] - 1s 708us/step - loss: 0.0400 - f1_weighted: 0.7619\n",
            "Epoch 7/300\n",
            "1750/1750 [==============================] - 1s 710us/step - loss: 0.0354 - f1_weighted: 0.7719\n",
            "Epoch 8/300\n",
            "1750/1750 [==============================] - 1s 759us/step - loss: 0.0330 - f1_weighted: 0.7840\n",
            "Epoch 9/300\n",
            "1750/1750 [==============================] - 1s 745us/step - loss: 0.0305 - f1_weighted: 0.7864\n",
            "Epoch 10/300\n",
            "1750/1750 [==============================] - 1s 778us/step - loss: 0.0293 - f1_weighted: 0.7886\n",
            "Epoch 11/300\n",
            "1750/1750 [==============================] - 1s 768us/step - loss: 0.0253 - f1_weighted: 0.8079\n",
            "Epoch 12/300\n",
            "1750/1750 [==============================] - 1s 760us/step - loss: 0.0248 - f1_weighted: 0.8108\n",
            "Epoch 13/300\n",
            "1750/1750 [==============================] - 1s 747us/step - loss: 0.0225 - f1_weighted: 0.8287\n",
            "Epoch 14/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0230 - f1_weighted: 0.8123\n",
            "Epoch 15/300\n",
            "1750/1750 [==============================] - 1s 734us/step - loss: 0.0220 - f1_weighted: 0.8295\n",
            "Epoch 16/300\n",
            "1750/1750 [==============================] - 1s 783us/step - loss: 0.0208 - f1_weighted: 0.8287\n",
            "Epoch 17/300\n",
            "1750/1750 [==============================] - 1s 768us/step - loss: 0.0192 - f1_weighted: 0.8344\n",
            "Epoch 18/300\n",
            "1750/1750 [==============================] - 1s 770us/step - loss: 0.0195 - f1_weighted: 0.8334\n",
            "Epoch 19/300\n",
            "1750/1750 [==============================] - 1s 744us/step - loss: 0.0185 - f1_weighted: 0.8470\n",
            "Epoch 20/300\n",
            "1750/1750 [==============================] - 1s 742us/step - loss: 0.0176 - f1_weighted: 0.8468\n",
            "Epoch 21/300\n",
            "1750/1750 [==============================] - 1s 710us/step - loss: 0.0162 - f1_weighted: 0.8462\n",
            "Epoch 22/300\n",
            "1750/1750 [==============================] - 1s 744us/step - loss: 0.0170 - f1_weighted: 0.8473\n",
            "Epoch 23/300\n",
            "1750/1750 [==============================] - 1s 748us/step - loss: 0.0150 - f1_weighted: 0.8580\n",
            "Epoch 24/300\n",
            "1750/1750 [==============================] - 1s 713us/step - loss: 0.0143 - f1_weighted: 0.8482\n",
            "Epoch 25/300\n",
            "1750/1750 [==============================] - 1s 712us/step - loss: 0.0151 - f1_weighted: 0.8590\n",
            "Epoch 26/300\n",
            "1750/1750 [==============================] - 1s 729us/step - loss: 0.0138 - f1_weighted: 0.8508\n",
            "Epoch 27/300\n",
            "1750/1750 [==============================] - 1s 736us/step - loss: 0.0136 - f1_weighted: 0.8611\n",
            "Epoch 28/300\n",
            "1750/1750 [==============================] - 1s 717us/step - loss: 0.0146 - f1_weighted: 0.8494\n",
            "Epoch 29/300\n",
            "1750/1750 [==============================] - 1s 710us/step - loss: 0.0115 - f1_weighted: 0.8692\n",
            "Epoch 30/300\n",
            "1750/1750 [==============================] - 1s 709us/step - loss: 0.0132 - f1_weighted: 0.8670\n",
            "Epoch 31/300\n",
            "1750/1750 [==============================] - 1s 737us/step - loss: 0.0130 - f1_weighted: 0.8562\n",
            "Epoch 32/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0109 - f1_weighted: 0.8776\n",
            "Epoch 33/300\n",
            "1750/1750 [==============================] - 1s 719us/step - loss: 0.0114 - f1_weighted: 0.8649\n",
            "Epoch 34/300\n",
            "1750/1750 [==============================] - 1s 716us/step - loss: 0.0109 - f1_weighted: 0.8710\n",
            "Epoch 35/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0113 - f1_weighted: 0.8684\n",
            "Epoch 36/300\n",
            "1750/1750 [==============================] - 1s 735us/step - loss: 0.0105 - f1_weighted: 0.8765\n",
            "Epoch 37/300\n",
            "1750/1750 [==============================] - 1s 726us/step - loss: 0.0092 - f1_weighted: 0.8816\n",
            "Epoch 38/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0102 - f1_weighted: 0.8803\n",
            "Epoch 39/300\n",
            "1750/1750 [==============================] - 1s 730us/step - loss: 0.0096 - f1_weighted: 0.8790\n",
            "Epoch 40/300\n",
            "1750/1750 [==============================] - 1s 766us/step - loss: 0.0098 - f1_weighted: 0.8801\n",
            "Epoch 41/300\n",
            "1750/1750 [==============================] - 1s 772us/step - loss: 0.0090 - f1_weighted: 0.8810\n",
            "Epoch 42/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0092 - f1_weighted: 0.8821\n",
            "Epoch 43/300\n",
            "1750/1750 [==============================] - 1s 736us/step - loss: 0.0094 - f1_weighted: 0.8769\n",
            "Epoch 44/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0085 - f1_weighted: 0.8760\n",
            "Epoch 45/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0099 - f1_weighted: 0.8766\n",
            "Epoch 46/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0093 - f1_weighted: 0.8806\n",
            "Epoch 47/300\n",
            "1750/1750 [==============================] - 1s 738us/step - loss: 0.0073 - f1_weighted: 0.8794\n",
            "Epoch 48/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0088 - f1_weighted: 0.8711\n",
            "Epoch 49/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0080 - f1_weighted: 0.8823\n",
            "Epoch 50/300\n",
            "1750/1750 [==============================] - 1s 721us/step - loss: 0.0074 - f1_weighted: 0.8738\n",
            "Epoch 51/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0093 - f1_weighted: 0.8849\n",
            "Epoch 52/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0074 - f1_weighted: 0.8838\n",
            "Epoch 53/300\n",
            "1750/1750 [==============================] - 1s 731us/step - loss: 0.0076 - f1_weighted: 0.8772\n",
            "Epoch 54/300\n",
            "1750/1750 [==============================] - 1s 727us/step - loss: 0.0077 - f1_weighted: 0.8725\n",
            "Epoch 55/300\n",
            "1750/1750 [==============================] - 1s 729us/step - loss: 0.0070 - f1_weighted: 0.8927\n",
            "Epoch 56/300\n",
            "1750/1750 [==============================] - 1s 724us/step - loss: 0.0080 - f1_weighted: 0.8885\n",
            "Epoch 57/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0065 - f1_weighted: 0.8919\n",
            "Epoch 58/300\n",
            "1750/1750 [==============================] - 1s 720us/step - loss: 0.0069 - f1_weighted: 0.9032\n",
            "Epoch 59/300\n",
            "1750/1750 [==============================] - 1s 740us/step - loss: 0.0065 - f1_weighted: 0.8979\n",
            "Epoch 60/300\n",
            "1750/1750 [==============================] - 1s 737us/step - loss: 0.0075 - f1_weighted: 0.8884\n",
            "Epoch 61/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0069 - f1_weighted: 0.8891\n",
            "Epoch 62/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0060 - f1_weighted: 0.9005\n",
            "Epoch 63/300\n",
            "1750/1750 [==============================] - 1s 716us/step - loss: 0.0066 - f1_weighted: 0.8948\n",
            "Epoch 64/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0072 - f1_weighted: 0.8935\n",
            "Epoch 65/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0065 - f1_weighted: 0.8890\n",
            "Epoch 66/300\n",
            "1750/1750 [==============================] - 1s 734us/step - loss: 0.0073 - f1_weighted: 0.8899\n",
            "Epoch 67/300\n",
            "1750/1750 [==============================] - 1s 745us/step - loss: 0.0058 - f1_weighted: 0.8927\n",
            "Epoch 68/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0062 - f1_weighted: 0.8837\n",
            "Epoch 69/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0057 - f1_weighted: 0.8897\n",
            "Epoch 70/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0059 - f1_weighted: 0.8932\n",
            "Epoch 71/300\n",
            "1750/1750 [==============================] - 1s 720us/step - loss: 0.0060 - f1_weighted: 0.8842\n",
            "Epoch 72/300\n",
            "1750/1750 [==============================] - 1s 777us/step - loss: 0.0060 - f1_weighted: 0.8878\n",
            "Epoch 73/300\n",
            "1750/1750 [==============================] - 1s 735us/step - loss: 0.0059 - f1_weighted: 0.8857\n",
            "Epoch 74/300\n",
            "1750/1750 [==============================] - 1s 731us/step - loss: 0.0058 - f1_weighted: 0.8952\n",
            "Epoch 75/300\n",
            "1750/1750 [==============================] - 1s 739us/step - loss: 0.0054 - f1_weighted: 0.8998\n",
            "Epoch 76/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 1s 753us/step - loss: 0.0069 - f1_weighted: 0.8814\n",
            "Epoch 77/300\n",
            "1750/1750 [==============================] - 1s 757us/step - loss: 0.0060 - f1_weighted: 0.8961\n",
            "Epoch 78/300\n",
            "1750/1750 [==============================] - 1s 783us/step - loss: 0.0069 - f1_weighted: 0.8827\n",
            "Epoch 79/300\n",
            "1750/1750 [==============================] - 1s 782us/step - loss: 0.0051 - f1_weighted: 0.8993\n",
            "Epoch 80/300\n",
            "1750/1750 [==============================] - 1s 777us/step - loss: 0.0056 - f1_weighted: 0.8953\n",
            "Epoch 81/300\n",
            "1750/1750 [==============================] - 1s 812us/step - loss: 0.0056 - f1_weighted: 0.9006\n",
            "Epoch 82/300\n",
            "1750/1750 [==============================] - 1s 765us/step - loss: 0.0060 - f1_weighted: 0.8987\n",
            "Epoch 83/300\n",
            "1750/1750 [==============================] - 1s 759us/step - loss: 0.0052 - f1_weighted: 0.9016\n",
            "Epoch 84/300\n",
            "1750/1750 [==============================] - 1s 754us/step - loss: 0.0053 - f1_weighted: 0.8849\n",
            "Epoch 85/300\n",
            "1750/1750 [==============================] - 1s 758us/step - loss: 0.0060 - f1_weighted: 0.8992\n",
            "Epoch 86/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0049 - f1_weighted: 0.8992\n",
            "Epoch 87/300\n",
            "1750/1750 [==============================] - 1s 762us/step - loss: 0.0064 - f1_weighted: 0.8947\n",
            "Epoch 88/300\n",
            "1750/1750 [==============================] - 1s 771us/step - loss: 0.0054 - f1_weighted: 0.9092\n",
            "Epoch 89/300\n",
            "1750/1750 [==============================] - 1s 775us/step - loss: 0.0055 - f1_weighted: 0.8893\n",
            "Epoch 90/300\n",
            "1750/1750 [==============================] - 1s 803us/step - loss: 0.0049 - f1_weighted: 0.9043\n",
            "Epoch 91/300\n",
            "1750/1750 [==============================] - 1s 750us/step - loss: 0.0050 - f1_weighted: 0.9014\n",
            "Epoch 92/300\n",
            "1750/1750 [==============================] - 1s 727us/step - loss: 0.0066 - f1_weighted: 0.8813\n",
            "Epoch 93/300\n",
            "1750/1750 [==============================] - 1s 730us/step - loss: 0.0045 - f1_weighted: 0.9055\n",
            "Epoch 94/300\n",
            "1750/1750 [==============================] - 1s 731us/step - loss: 0.0045 - f1_weighted: 0.8954\n",
            "Epoch 95/300\n",
            "1750/1750 [==============================] - 1s 740us/step - loss: 0.0038 - f1_weighted: 0.9043\n",
            "Epoch 96/300\n",
            "1750/1750 [==============================] - 1s 765us/step - loss: 0.0053 - f1_weighted: 0.8929\n",
            "Epoch 97/300\n",
            "1750/1750 [==============================] - 1s 729us/step - loss: 0.0044 - f1_weighted: 0.8888\n",
            "Epoch 98/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0051 - f1_weighted: 0.8939\n",
            "Epoch 99/300\n",
            "1750/1750 [==============================] - 1s 777us/step - loss: 0.0051 - f1_weighted: 0.8938\n",
            "Epoch 100/300\n",
            "1750/1750 [==============================] - 1s 752us/step - loss: 0.0048 - f1_weighted: 0.8860\n",
            "Epoch 101/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0038 - f1_weighted: 0.8992\n",
            "Epoch 102/300\n",
            "1750/1750 [==============================] - 1s 790us/step - loss: 0.0046 - f1_weighted: 0.8940\n",
            "Epoch 103/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0050 - f1_weighted: 0.9001\n",
            "Epoch 104/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0041 - f1_weighted: 0.9041\n",
            "Epoch 105/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0054 - f1_weighted: 0.8999\n",
            "Epoch 106/300\n",
            "1750/1750 [==============================] - 1s 745us/step - loss: 0.0040 - f1_weighted: 0.8992\n",
            "Epoch 107/300\n",
            "1750/1750 [==============================] - 1s 752us/step - loss: 0.0046 - f1_weighted: 0.8987\n",
            "Epoch 108/300\n",
            "1750/1750 [==============================] - 1s 737us/step - loss: 0.0051 - f1_weighted: 0.8942\n",
            "Epoch 109/300\n",
            "1750/1750 [==============================] - 1s 737us/step - loss: 0.0051 - f1_weighted: 0.8904\n",
            "Epoch 110/300\n",
            "1750/1750 [==============================] - 1s 731us/step - loss: 0.0051 - f1_weighted: 0.9038\n",
            "Epoch 111/300\n",
            "1750/1750 [==============================] - 1s 749us/step - loss: 0.0040 - f1_weighted: 0.9061\n",
            "Epoch 112/300\n",
            "1750/1750 [==============================] - 1s 736us/step - loss: 0.0038 - f1_weighted: 0.9066\n",
            "Epoch 113/300\n",
            "1750/1750 [==============================] - 1s 751us/step - loss: 0.0051 - f1_weighted: 0.8958\n",
            "Epoch 114/300\n",
            "1750/1750 [==============================] - 1s 749us/step - loss: 0.0031 - f1_weighted: 0.9119\n",
            "Epoch 115/300\n",
            "1750/1750 [==============================] - 1s 742us/step - loss: 0.0046 - f1_weighted: 0.8972\n",
            "Epoch 116/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0039 - f1_weighted: 0.9025\n",
            "Epoch 117/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0036 - f1_weighted: 0.9011\n",
            "Epoch 118/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0044 - f1_weighted: 0.9043\n",
            "Epoch 119/300\n",
            "1750/1750 [==============================] - 1s 743us/step - loss: 0.0041 - f1_weighted: 0.9205\n",
            "Epoch 120/300\n",
            "1750/1750 [==============================] - 1s 736us/step - loss: 0.0044 - f1_weighted: 0.9055\n",
            "Epoch 121/300\n",
            "1750/1750 [==============================] - 1s 745us/step - loss: 0.0045 - f1_weighted: 0.9008\n",
            "Epoch 122/300\n",
            "1750/1750 [==============================] - 1s 737us/step - loss: 0.0039 - f1_weighted: 0.8955\n",
            "Epoch 123/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0037 - f1_weighted: 0.9025\n",
            "Epoch 124/300\n",
            "1750/1750 [==============================] - 1s 728us/step - loss: 0.0037 - f1_weighted: 0.8910\n",
            "Epoch 125/300\n",
            "1750/1750 [==============================] - 1s 729us/step - loss: 0.0046 - f1_weighted: 0.9018\n",
            "Epoch 126/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0037 - f1_weighted: 0.9135\n",
            "Epoch 127/300\n",
            "1750/1750 [==============================] - 1s 756us/step - loss: 0.0044 - f1_weighted: 0.9128\n",
            "Epoch 128/300\n",
            "1750/1750 [==============================] - 1s 747us/step - loss: 0.0034 - f1_weighted: 0.8952\n",
            "Epoch 129/300\n",
            "1750/1750 [==============================] - 1s 735us/step - loss: 0.0034 - f1_weighted: 0.9137\n",
            "Epoch 130/300\n",
            "1750/1750 [==============================] - 1s 739us/step - loss: 0.0037 - f1_weighted: 0.8992\n",
            "Epoch 131/300\n",
            "1750/1750 [==============================] - 1s 740us/step - loss: 0.0048 - f1_weighted: 0.8934\n",
            "Epoch 132/300\n",
            "1750/1750 [==============================] - 1s 744us/step - loss: 0.0048 - f1_weighted: 0.9006\n",
            "Epoch 133/300\n",
            "1750/1750 [==============================] - 1s 750us/step - loss: 0.0036 - f1_weighted: 0.9173\n",
            "Epoch 134/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0031 - f1_weighted: 0.9030\n",
            "Epoch 135/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0044 - f1_weighted: 0.9049\n",
            "Epoch 136/300\n",
            "1750/1750 [==============================] - 1s 750us/step - loss: 0.0038 - f1_weighted: 0.8876\n",
            "Epoch 137/300\n",
            "1750/1750 [==============================] - 1s 756us/step - loss: 0.0040 - f1_weighted: 0.9011\n",
            "Epoch 138/300\n",
            "1750/1750 [==============================] - 1s 731us/step - loss: 0.0045 - f1_weighted: 0.9037\n",
            "Epoch 139/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0042 - f1_weighted: 0.9005\n",
            "Epoch 140/300\n",
            "1750/1750 [==============================] - 1s 775us/step - loss: 0.0034 - f1_weighted: 0.9009\n",
            "Epoch 141/300\n",
            "1750/1750 [==============================] - 1s 779us/step - loss: 0.0035 - f1_weighted: 0.9010\n",
            "Epoch 142/300\n",
            "1750/1750 [==============================] - 1s 758us/step - loss: 0.0048 - f1_weighted: 0.9045\n",
            "Epoch 143/300\n",
            "1750/1750 [==============================] - 1s 743us/step - loss: 0.0038 - f1_weighted: 0.9042\n",
            "Epoch 144/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0040 - f1_weighted: 0.8983\n",
            "Epoch 145/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0038 - f1_weighted: 0.9081\n",
            "Epoch 146/300\n",
            "1750/1750 [==============================] - 1s 828us/step - loss: 0.0040 - f1_weighted: 0.8975\n",
            "Epoch 147/300\n",
            "1750/1750 [==============================] - 1s 749us/step - loss: 0.0038 - f1_weighted: 0.9150\n",
            "Epoch 148/300\n",
            "1750/1750 [==============================] - 1s 771us/step - loss: 0.0053 - f1_weighted: 0.8957\n",
            "Epoch 149/300\n",
            "1750/1750 [==============================] - 1s 749us/step - loss: 0.0040 - f1_weighted: 0.8897\n",
            "Epoch 150/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 1s 747us/step - loss: 0.0038 - f1_weighted: 0.8959\n",
            "Epoch 151/300\n",
            "1750/1750 [==============================] - 1s 744us/step - loss: 0.0029 - f1_weighted: 0.9092\n",
            "Epoch 152/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0041 - f1_weighted: 0.8992\n",
            "Epoch 153/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0044 - f1_weighted: 0.8888\n",
            "Epoch 154/300\n",
            "1750/1750 [==============================] - 1s 742us/step - loss: 0.0019 - f1_weighted: 0.9123\n",
            "Epoch 155/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0046 - f1_weighted: 0.8970\n",
            "Epoch 156/300\n",
            "1750/1750 [==============================] - 1s 717us/step - loss: 0.0042 - f1_weighted: 0.9080\n",
            "Epoch 157/300\n",
            "1750/1750 [==============================] - 1s 712us/step - loss: 0.0044 - f1_weighted: 0.9057\n",
            "Epoch 158/300\n",
            "1750/1750 [==============================] - 1s 737us/step - loss: 0.0032 - f1_weighted: 0.9104\n",
            "Epoch 159/300\n",
            "1750/1750 [==============================] - 1s 738us/step - loss: 0.0040 - f1_weighted: 0.9049\n",
            "Epoch 160/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0037 - f1_weighted: 0.8841\n",
            "Epoch 161/300\n",
            "1750/1750 [==============================] - 1s 735us/step - loss: 0.0030 - f1_weighted: 0.9120\n",
            "Epoch 162/300\n",
            "1750/1750 [==============================] - 1s 720us/step - loss: 0.0032 - f1_weighted: 0.9067\n",
            "Epoch 163/300\n",
            "1750/1750 [==============================] - 1s 763us/step - loss: 0.0041 - f1_weighted: 0.9037\n",
            "Epoch 164/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0040 - f1_weighted: 0.8999\n",
            "Epoch 165/300\n",
            "1750/1750 [==============================] - 1s 743us/step - loss: 0.0046 - f1_weighted: 0.8913\n",
            "Epoch 166/300\n",
            "1750/1750 [==============================] - 1s 726us/step - loss: 0.0034 - f1_weighted: 0.9010\n",
            "Epoch 167/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0044 - f1_weighted: 0.8956\n",
            "Epoch 168/300\n",
            "1750/1750 [==============================] - 1s 724us/step - loss: 0.0034 - f1_weighted: 0.8979\n",
            "Epoch 169/300\n",
            "1750/1750 [==============================] - 1s 709us/step - loss: 0.0036 - f1_weighted: 0.9155\n",
            "Epoch 170/300\n",
            "1750/1750 [==============================] - 1s 717us/step - loss: 0.0026 - f1_weighted: 0.8916\n",
            "Epoch 171/300\n",
            "1750/1750 [==============================] - 1s 708us/step - loss: 0.0039 - f1_weighted: 0.9133\n",
            "Epoch 172/300\n",
            "1750/1750 [==============================] - 1s 706us/step - loss: 0.0035 - f1_weighted: 0.9108\n",
            "Epoch 173/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0034 - f1_weighted: 0.9111\n",
            "Epoch 174/300\n",
            "1750/1750 [==============================] - 1s 726us/step - loss: 0.0038 - f1_weighted: 0.9000\n",
            "Epoch 175/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0046 - f1_weighted: 0.8913\n",
            "Epoch 176/300\n",
            "1750/1750 [==============================] - 1s 734us/step - loss: 0.0026 - f1_weighted: 0.9118\n",
            "Epoch 177/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0027 - f1_weighted: 0.9058\n",
            "Epoch 178/300\n",
            "1750/1750 [==============================] - 1s 728us/step - loss: 0.0041 - f1_weighted: 0.8970\n",
            "Epoch 179/300\n",
            "1750/1750 [==============================] - 1s 717us/step - loss: 0.0033 - f1_weighted: 0.8988\n",
            "Epoch 180/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0034 - f1_weighted: 0.9060\n",
            "Epoch 181/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0036 - f1_weighted: 0.8997\n",
            "Epoch 182/300\n",
            "1750/1750 [==============================] - 1s 733us/step - loss: 0.0047 - f1_weighted: 0.8997\n",
            "Epoch 183/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0034 - f1_weighted: 0.9046\n",
            "Epoch 184/300\n",
            "1750/1750 [==============================] - 1s 738us/step - loss: 0.0041 - f1_weighted: 0.9091\n",
            "Epoch 185/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0031 - f1_weighted: 0.9048\n",
            "Epoch 186/300\n",
            "1750/1750 [==============================] - 1s 729us/step - loss: 0.0039 - f1_weighted: 0.8960\n",
            "Epoch 187/300\n",
            "1750/1750 [==============================] - 1s 717us/step - loss: 0.0038 - f1_weighted: 0.9028\n",
            "Epoch 188/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0035 - f1_weighted: 0.8985\n",
            "Epoch 189/300\n",
            "1750/1750 [==============================] - 1s 769us/step - loss: 0.0031 - f1_weighted: 0.9074\n",
            "Epoch 190/300\n",
            "1750/1750 [==============================] - 1s 736us/step - loss: 0.0028 - f1_weighted: 0.9122\n",
            "Epoch 191/300\n",
            "1750/1750 [==============================] - 1s 710us/step - loss: 0.0031 - f1_weighted: 0.9076\n",
            "Epoch 192/300\n",
            "1750/1750 [==============================] - 1s 703us/step - loss: 0.0033 - f1_weighted: 0.9086\n",
            "Epoch 193/300\n",
            "1750/1750 [==============================] - 1s 708us/step - loss: 0.0037 - f1_weighted: 0.8944\n",
            "Epoch 194/300\n",
            "1750/1750 [==============================] - 1s 707us/step - loss: 0.0038 - f1_weighted: 0.8996\n",
            "Epoch 195/300\n",
            "1750/1750 [==============================] - 1s 706us/step - loss: 0.0026 - f1_weighted: 0.9142\n",
            "Epoch 196/300\n",
            "1750/1750 [==============================] - 1s 738us/step - loss: 0.0032 - f1_weighted: 0.8999\n",
            "Epoch 197/300\n",
            "1750/1750 [==============================] - 1s 753us/step - loss: 0.0022 - f1_weighted: 0.9163\n",
            "Epoch 198/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0029 - f1_weighted: 0.9191\n",
            "Epoch 199/300\n",
            "1750/1750 [==============================] - 1s 740us/step - loss: 0.0042 - f1_weighted: 0.8981\n",
            "Epoch 200/300\n",
            "1750/1750 [==============================] - 1s 767us/step - loss: 0.0037 - f1_weighted: 0.9051\n",
            "Epoch 201/300\n",
            "1750/1750 [==============================] - 1s 806us/step - loss: 0.0024 - f1_weighted: 0.9249\n",
            "Epoch 202/300\n",
            "1750/1750 [==============================] - 1s 815us/step - loss: 0.0041 - f1_weighted: 0.9098\n",
            "Epoch 203/300\n",
            "1750/1750 [==============================] - 1s 749us/step - loss: 0.0025 - f1_weighted: 0.9142\n",
            "Epoch 204/300\n",
            "1750/1750 [==============================] - 1s 802us/step - loss: 0.0028 - f1_weighted: 0.9132\n",
            "Epoch 205/300\n",
            "1750/1750 [==============================] - 1s 820us/step - loss: 0.0032 - f1_weighted: 0.9084\n",
            "Epoch 206/300\n",
            "1750/1750 [==============================] - 1s 785us/step - loss: 0.0042 - f1_weighted: 0.9047\n",
            "Epoch 207/300\n",
            "1750/1750 [==============================] - 1s 742us/step - loss: 0.0038 - f1_weighted: 0.9067\n",
            "Epoch 208/300\n",
            "1750/1750 [==============================] - 1s 753us/step - loss: 0.0037 - f1_weighted: 0.9051\n",
            "Epoch 209/300\n",
            "1750/1750 [==============================] - 1s 744us/step - loss: 0.0032 - f1_weighted: 0.9163\n",
            "Epoch 210/300\n",
            "1750/1750 [==============================] - 1s 748us/step - loss: 0.0035 - f1_weighted: 0.9094\n",
            "Epoch 211/300\n",
            "1750/1750 [==============================] - 1s 739us/step - loss: 0.0033 - f1_weighted: 0.8956\n",
            "Epoch 212/300\n",
            "1750/1750 [==============================] - 1s 745us/step - loss: 0.0026 - f1_weighted: 0.9113\n",
            "Epoch 213/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0043 - f1_weighted: 0.9034\n",
            "Epoch 214/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0033 - f1_weighted: 0.9043\n",
            "Epoch 215/300\n",
            "1750/1750 [==============================] - 1s 761us/step - loss: 0.0030 - f1_weighted: 0.9062\n",
            "Epoch 216/300\n",
            "1750/1750 [==============================] - 1s 752us/step - loss: 0.0029 - f1_weighted: 0.9167\n",
            "Epoch 217/300\n",
            "1750/1750 [==============================] - 1s 744us/step - loss: 0.0037 - f1_weighted: 0.8991\n",
            "Epoch 218/300\n",
            "1750/1750 [==============================] - 1s 727us/step - loss: 0.0037 - f1_weighted: 0.9050\n",
            "Epoch 219/300\n",
            "1750/1750 [==============================] - 1s 748us/step - loss: 0.0039 - f1_weighted: 0.9010\n",
            "Epoch 220/300\n",
            "1750/1750 [==============================] - 1s 755us/step - loss: 0.0036 - f1_weighted: 0.8971\n",
            "Epoch 221/300\n",
            "1750/1750 [==============================] - 1s 763us/step - loss: 0.0021 - f1_weighted: 0.9016\n",
            "Epoch 222/300\n",
            "1750/1750 [==============================] - 1s 763us/step - loss: 0.0036 - f1_weighted: 0.9112\n",
            "Epoch 223/300\n",
            "1750/1750 [==============================] - 1s 764us/step - loss: 0.0037 - f1_weighted: 0.9095\n",
            "Epoch 224/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 1s 747us/step - loss: 0.0032 - f1_weighted: 0.9017\n",
            "Epoch 225/300\n",
            "1750/1750 [==============================] - 1s 778us/step - loss: 0.0030 - f1_weighted: 0.8989\n",
            "Epoch 226/300\n",
            "1750/1750 [==============================] - 1s 769us/step - loss: 0.0023 - f1_weighted: 0.9069\n",
            "Epoch 227/300\n",
            "1750/1750 [==============================] - 1s 748us/step - loss: 0.0040 - f1_weighted: 0.9107\n",
            "Epoch 228/300\n",
            "1750/1750 [==============================] - 1s 742us/step - loss: 0.0034 - f1_weighted: 0.8955\n",
            "Epoch 229/300\n",
            "1750/1750 [==============================] - 1s 747us/step - loss: 0.0031 - f1_weighted: 0.9041\n",
            "Epoch 230/300\n",
            "1750/1750 [==============================] - 1s 743us/step - loss: 0.0024 - f1_weighted: 0.9082\n",
            "Epoch 231/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0024 - f1_weighted: 0.9024\n",
            "Epoch 232/300\n",
            "1750/1750 [==============================] - 1s 727us/step - loss: 0.0029 - f1_weighted: 0.9212\n",
            "Epoch 233/300\n",
            "1750/1750 [==============================] - 1s 721us/step - loss: 0.0026 - f1_weighted: 0.9273\n",
            "Epoch 234/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0032 - f1_weighted: 0.9177\n",
            "Epoch 235/300\n",
            "1750/1750 [==============================] - 1s 734us/step - loss: 0.0034 - f1_weighted: 0.9146\n",
            "Epoch 236/300\n",
            "1750/1750 [==============================] - 1s 748us/step - loss: 0.0032 - f1_weighted: 0.9070\n",
            "Epoch 237/300\n",
            "1750/1750 [==============================] - 1s 782us/step - loss: 0.0032 - f1_weighted: 0.9187\n",
            "Epoch 238/300\n",
            "1750/1750 [==============================] - 1s 782us/step - loss: 0.0026 - f1_weighted: 0.9201\n",
            "Epoch 239/300\n",
            "1750/1750 [==============================] - 1s 843us/step - loss: 0.0033 - f1_weighted: 0.9050\n",
            "Epoch 240/300\n",
            "1750/1750 [==============================] - 1s 772us/step - loss: 0.0028 - f1_weighted: 0.9163\n",
            "Epoch 241/300\n",
            "1750/1750 [==============================] - 1s 780us/step - loss: 0.0032 - f1_weighted: 0.9133\n",
            "Epoch 242/300\n",
            "1750/1750 [==============================] - 1s 757us/step - loss: 0.0038 - f1_weighted: 0.9049\n",
            "Epoch 243/300\n",
            "1750/1750 [==============================] - 1s 760us/step - loss: 0.0025 - f1_weighted: 0.9070\n",
            "Epoch 244/300\n",
            "1750/1750 [==============================] - 1s 716us/step - loss: 0.0029 - f1_weighted: 0.9134\n",
            "Epoch 245/300\n",
            "1750/1750 [==============================] - 1s 707us/step - loss: 0.0028 - f1_weighted: 0.9119\n",
            "Epoch 246/300\n",
            "1750/1750 [==============================] - 1s 714us/step - loss: 0.0028 - f1_weighted: 0.9101\n",
            "Epoch 247/300\n",
            "1750/1750 [==============================] - 1s 712us/step - loss: 0.0023 - f1_weighted: 0.9205\n",
            "Epoch 248/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0039 - f1_weighted: 0.9098\n",
            "Epoch 249/300\n",
            "1750/1750 [==============================] - 1s 722us/step - loss: 0.0026 - f1_weighted: 0.9146\n",
            "Epoch 250/300\n",
            "1750/1750 [==============================] - 1s 715us/step - loss: 0.0030 - f1_weighted: 0.9011\n",
            "Epoch 251/300\n",
            "1750/1750 [==============================] - 1s 716us/step - loss: 0.0031 - f1_weighted: 0.9224\n",
            "Epoch 252/300\n",
            "1750/1750 [==============================] - 1s 714us/step - loss: 0.0032 - f1_weighted: 0.9104\n",
            "Epoch 253/300\n",
            "1750/1750 [==============================] - 1s 711us/step - loss: 0.0030 - f1_weighted: 0.9151\n",
            "Epoch 254/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0032 - f1_weighted: 0.9055\n",
            "Epoch 255/300\n",
            "1750/1750 [==============================] - 1s 710us/step - loss: 0.0028 - f1_weighted: 0.9152\n",
            "Epoch 256/300\n",
            "1750/1750 [==============================] - 1s 715us/step - loss: 0.0035 - f1_weighted: 0.9159\n",
            "Epoch 257/300\n",
            "1750/1750 [==============================] - 1s 711us/step - loss: 0.0030 - f1_weighted: 0.9064\n",
            "Epoch 258/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0035 - f1_weighted: 0.9031\n",
            "Epoch 259/300\n",
            "1750/1750 [==============================] - 1s 717us/step - loss: 0.0024 - f1_weighted: 0.9081\n",
            "Epoch 260/300\n",
            "1750/1750 [==============================] - 1s 704us/step - loss: 0.0028 - f1_weighted: 0.9083\n",
            "Epoch 261/300\n",
            "1750/1750 [==============================] - 1s 710us/step - loss: 0.0044 - f1_weighted: 0.9129\n",
            "Epoch 262/300\n",
            "1750/1750 [==============================] - 1s 712us/step - loss: 0.0032 - f1_weighted: 0.9076\n",
            "Epoch 263/300\n",
            "1750/1750 [==============================] - 1s 723us/step - loss: 0.0026 - f1_weighted: 0.9164\n",
            "Epoch 264/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0027 - f1_weighted: 0.9190\n",
            "Epoch 265/300\n",
            "1750/1750 [==============================] - 1s 700us/step - loss: 0.0025 - f1_weighted: 0.9152\n",
            "Epoch 266/300\n",
            "1750/1750 [==============================] - 1s 711us/step - loss: 0.0028 - f1_weighted: 0.9198\n",
            "Epoch 267/300\n",
            "1750/1750 [==============================] - 1s 747us/step - loss: 0.0032 - f1_weighted: 0.9090\n",
            "Epoch 268/300\n",
            "1750/1750 [==============================] - 1s 703us/step - loss: 0.0032 - f1_weighted: 0.9083\n",
            "Epoch 269/300\n",
            "1750/1750 [==============================] - 1s 701us/step - loss: 0.0028 - f1_weighted: 0.8996\n",
            "Epoch 270/300\n",
            "1750/1750 [==============================] - 1s 702us/step - loss: 0.0030 - f1_weighted: 0.8979\n",
            "Epoch 271/300\n",
            "1750/1750 [==============================] - 1s 699us/step - loss: 0.0031 - f1_weighted: 0.9012\n",
            "Epoch 272/300\n",
            "1750/1750 [==============================] - 1s 699us/step - loss: 0.0031 - f1_weighted: 0.9109\n",
            "Epoch 273/300\n",
            "1750/1750 [==============================] - 1s 703us/step - loss: 0.0027 - f1_weighted: 0.9073\n",
            "Epoch 274/300\n",
            "1750/1750 [==============================] - 1s 714us/step - loss: 0.0030 - f1_weighted: 0.9141\n",
            "Epoch 275/300\n",
            "1750/1750 [==============================] - 1s 712us/step - loss: 0.0030 - f1_weighted: 0.9103\n",
            "Epoch 276/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0036 - f1_weighted: 0.9115\n",
            "Epoch 277/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0031 - f1_weighted: 0.9101\n",
            "Epoch 278/300\n",
            "1750/1750 [==============================] - 1s 745us/step - loss: 0.0020 - f1_weighted: 0.9119\n",
            "Epoch 279/300\n",
            "1750/1750 [==============================] - 1s 716us/step - loss: 0.0028 - f1_weighted: 0.9153\n",
            "Epoch 280/300\n",
            "1750/1750 [==============================] - 1s 718us/step - loss: 0.0031 - f1_weighted: 0.9089\n",
            "Epoch 281/300\n",
            "1750/1750 [==============================] - 1s 706us/step - loss: 0.0037 - f1_weighted: 0.9038\n",
            "Epoch 282/300\n",
            "1750/1750 [==============================] - 1s 704us/step - loss: 0.0028 - f1_weighted: 0.9198\n",
            "Epoch 283/300\n",
            "1750/1750 [==============================] - 1s 720us/step - loss: 0.0025 - f1_weighted: 0.9056\n",
            "Epoch 284/300\n",
            "1750/1750 [==============================] - 1s 722us/step - loss: 0.0027 - f1_weighted: 0.9177\n",
            "Epoch 285/300\n",
            "1750/1750 [==============================] - 1s 732us/step - loss: 0.0028 - f1_weighted: 0.8995\n",
            "Epoch 286/300\n",
            "1750/1750 [==============================] - 1s 736us/step - loss: 0.0032 - f1_weighted: 0.9152\n",
            "Epoch 287/300\n",
            "1750/1750 [==============================] - 1s 727us/step - loss: 0.0027 - f1_weighted: 0.9062\n",
            "Epoch 288/300\n",
            "1750/1750 [==============================] - 1s 752us/step - loss: 0.0031 - f1_weighted: 0.9133\n",
            "Epoch 289/300\n",
            "1750/1750 [==============================] - 1s 728us/step - loss: 0.0032 - f1_weighted: 0.9065\n",
            "Epoch 290/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0032 - f1_weighted: 0.9064\n",
            "Epoch 291/300\n",
            "1750/1750 [==============================] - 1s 724us/step - loss: 0.0031 - f1_weighted: 0.9131\n",
            "Epoch 292/300\n",
            "1750/1750 [==============================] - 1s 713us/step - loss: 0.0029 - f1_weighted: 0.9119\n",
            "Epoch 293/300\n",
            "1750/1750 [==============================] - 1s 707us/step - loss: 0.0030 - f1_weighted: 0.9128\n",
            "Epoch 294/300\n",
            "1750/1750 [==============================] - 1s 713us/step - loss: 0.0021 - f1_weighted: 0.9035\n",
            "Epoch 295/300\n",
            "1750/1750 [==============================] - 1s 711us/step - loss: 0.0029 - f1_weighted: 0.9012\n",
            "Epoch 296/300\n",
            "1750/1750 [==============================] - 1s 749us/step - loss: 0.0031 - f1_weighted: 0.9082\n",
            "Epoch 297/300\n",
            "1750/1750 [==============================] - 1s 742us/step - loss: 0.0033 - f1_weighted: 0.9065\n",
            "Epoch 298/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0026 - f1_weighted: 0.9042\n",
            "Epoch 299/300\n",
            "1750/1750 [==============================] - 1s 725us/step - loss: 0.0031 - f1_weighted: 0.9022\n",
            "Epoch 300/300\n",
            "1750/1750 [==============================] - 1s 741us/step - loss: 0.0028 - f1_weighted: 0.9138\n",
            "WARNING:tensorflow:From <ipython-input-9-91efd4036bda>:14: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rKIKaTN0CHe",
        "outputId": "81c98def-d245-4cf7-87db-ee1255b853a8"
      },
      "source": [
        "y_pred = model.predict_classes(X_test.astype('int32'))\n",
        "print(f1_score(y_pred,y_test.astype('int')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m4nSb7EwEMg"
      },
      "source": [
        "## Output results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRZx4NCWwEMg",
        "scrolled": true,
        "outputId": "54abff2b-71c1-40fe-e956-187a04282f79"
      },
      "source": [
        "output = model.predict_classes(onehotencode(split(test_data[:,0])))\n",
        "print(output.shape)\n",
        "data = pd.Series(output.reshape(-1))\n",
        "data.to_csv(\"output.csv\",index=False,header=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7jM9wbJ0CHk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}